{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UGCA Project 1 Report\n",
    "We scraped all the comments in all the forums under the tires and wheels section of edmunds (42,890 comments)  \n",
    "https://forums.edmunds.com/discussions/tagged/x/tires-wheels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import and clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of comments scraped: 42890\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize,sent_tokenize\n",
    "from functools import reduce\n",
    "from collections import Counter\n",
    "\n",
    "with open(\"edmunds_comment_data.json\", 'r') as f:\n",
    "    js = json.load(f)\n",
    "\n",
    "commentcount = 0\n",
    "characterstoclean = r'?!,:,/\\\"-+=@#$%^&*()><{}[]|' + r\"'\"\n",
    "\n",
    "commentsdict = {}\n",
    "words = []\n",
    "for i in js.keys():\n",
    "    for j in js[i].keys():\n",
    "        for k in js[i][j].keys():\n",
    "            for l in js[i][j][k].keys():\n",
    "                commentcount+=1\n",
    "                cleanwords = []\n",
    "#                 for w in word_tokenize(js[i][j][k][l]):\n",
    "#                     cleanword = ''.join( c for c in w if c not in characterstoclean ).lower()\n",
    "#                     cleanwords.append(cleanword)\n",
    "#                     words.append(cleanword)\n",
    "                comment = ''\n",
    "                # to remove quoted content in comments, not 100% effective\n",
    "                for s in sent_tokenize(js[i][j][k][l].lower()):\n",
    "                    if \"said:\" not in s:\n",
    "                        comment+=\" \" + s\n",
    "                for c in characterstoclean:\n",
    "                    comment = comment.replace(c,'')\n",
    "                for w in word_tokenize(comment):\n",
    "                    cleanwords.append(w)\n",
    "                    words.append(w)                \n",
    "                \n",
    "                commentsdict['comment' + str(commentcount)] = ' '.join(cleanwords)\n",
    "                \n",
    "\n",
    "print(\"Number of comments scraped: \" + str(commentcount))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top 10 most frequently used words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = Counter(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import brown\n",
    "stopwords_set = set(stopwords.words('english'))\n",
    "brown_set = set(brown.words())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1) 'tires' appeared 23827 times\n",
      "2) 'tire' appeared 16121 times\n",
      "3) 'car' appeared 9481 times\n",
      "4) 'would' appeared 8370 times\n",
      "5) 'new' appeared 6485 times\n",
      "6) 'get' appeared 6235 times\n",
      "7) 'miles' appeared 5916 times\n",
      "8) 'like' appeared 5771 times\n",
      "9) 'one' appeared 5637 times\n",
      "10) 'good' appeared 5113 times\n"
     ]
    }
   ],
   "source": [
    "ranked_cnt = []\n",
    "for i in cnt:\n",
    "    if i not in stopwords_set and i not in characterstoclean and i != '.' and i != '...' :\n",
    "        ranked_cnt.append( (cnt[i], i) )\n",
    "ranked_cnt.sort(reverse=True)\n",
    "\n",
    "for i in range(len(ranked_cnt[:10])):\n",
    "    print(str(i+1) + \") '\" + str(ranked_cnt[i][1]) + \"' appeared \" + str(ranked_cnt[i][0]) + ' times')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: we removed stopwords from the above list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top 10 Mentioned Brands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1) the brand 'Michelin' appeared 2579 times\n",
      "2) the brand 'Bridgestone' appeared 1533 times\n",
      "3) the brand 'Goodyear' appeared 1358 times\n",
      "4) the brand 'Toyo' appeared 622 times\n",
      "5) the brand 'Firestone' appeared 531 times\n",
      "6) the brand 'Dunlop' appeared 499 times\n",
      "7) the brand 'Continental' appeared 450 times\n",
      "8) the brand 'Yokohama' appeared 441 times\n",
      "9) the brand 'General' appeared 398 times\n",
      "10) the brand 'Nokian' appeared 350 times\n"
     ]
    }
   ],
   "source": [
    "brands = ['BFGoodrich', 'Bridgestone', 'Continental', 'Cooper', 'Dunlop', 'Falken', 'Firestone', 'General', 'Goodyear', 'GT Radial', 'Hankook', 'Kumho', 'Michelin', 'Nexen', 'Nitto', 'Nokian', 'Pirelli', 'Sumitomo', 'Toyo', 'Uniroyal', 'Yokohama']\n",
    "brand_counts = []\n",
    "for i in brands:\n",
    "    brand_counts.append((i, cnt[i.lower()] ))\n",
    "\n",
    "brand_counts.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "for i in range(len(brand_counts[:10])):\n",
    "    print(str(i+1) + \") the brand '\" + str(brand_counts[i][0]) + \"' appeared \" + str(brand_counts[i][1]) + ' times')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get all the comments that mention goodyear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "goodyear_comments = {}\n",
    "for i in commentsdict:\n",
    "    if 'goodyear' in commentsdict[i]:\n",
    "        goodyear_comments[i] = commentsdict[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1381"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(goodyear_comments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get all the words used in comments that mention goodyear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_in_goodyear_comments = []\n",
    "for i in goodyear_comments:\n",
    "    for j in word_tokenize(goodyear_comments[i]):\n",
    "        words_in_goodyear_comments.append(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdyr_cnt = Counter(words_in_goodyear_comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(6110, 'the'),\n",
       " (5797, '.'),\n",
       " (3414, 'i'),\n",
       " (2700, 'and'),\n",
       " (2429, 'a'),\n",
       " (2167, 'to'),\n",
       " (2043, 'tires'),\n",
       " (1772, 'on'),\n",
       " (1390, 'of'),\n",
       " (1358, 'goodyear')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ranked_goyr_cnt = []\n",
    "for i in gdyr_cnt:\n",
    "    ranked_goyr_cnt.append( (gdyr_cnt[i], i) )\n",
    "ranked_goyr_cnt.sort(reverse=True)\n",
    "ranked_goyr_cnt[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comments with goodyear and ____ in them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comparisonstring = 'american'\n",
    "\n",
    "comments_with_gdyr_and = []\n",
    "for i in goodyear_comments:\n",
    "    if comparisonstring in goodyear_comments[i]:\n",
    "        comments_with_gdyr_and.append(goodyear_comments[i])\n",
    "len(comments_with_gdyr_and)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hey thanks for your response . i did have them install 2 new goodyear tires to replace the 2 that i had just purchased and they are just as bad . the goodyears that i have are called american eagles . is that a private labled model maybe i would be better off going to a different walmart maybe they carry a different tire for my car . maybe they have technicians that are nice . maybe just maybe .'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments_with_gdyr_and[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Possibly filter lift value to represent associations within a maximum word count  \n",
    "    Beto -- Healthcare (no more than 6 words in between)  \n",
    "mds map a disimilarity matrix, not similarity matrix"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
